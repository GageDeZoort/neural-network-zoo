{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Long Short-Term Memory for Sequential Predictions\n",
        "\n",
        "Gage DeZoort\\\n",
        "3/25/24\\\n",
        "\\\n",
        "Based on several helpful tutorials:\\\n",
        "[1] [LSTM for Time Series Prediction in PyTorch](https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/)\\\n",
        "[2] [Predicting airline passengers using LSTM and Tensorflow](https://matthewmacfarquhar.medium.com/predicting-airline-passengers-using-lstm-and-tensorflow-ab86347cf318)\n"
      ],
      "metadata": {
        "id": "EcsMvCfajcyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temperature Predictions"
      ],
      "metadata": {
        "id": "6kgvYxPHRET4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project is based on Long Short-Term Memory (LSTM) modules. LSTMs belong to the class of Recurent Neural Networks (RNNs), which operate on sequential data (ordered data, indexed by time or space). For example, the daily temperature is a time series we all experience:\n",
        "\n",
        "![Weather](https://www.influxdata.com/wp-content/uploads/time-series-data-weather-data.png \"weather\")\n",
        "(Image from [this article](https://www.influxdata.com/what-is-time-series-data/))\n",
        "\n",
        "Sentences are another example of sequential data:\n",
        "\n",
        "![Sentences](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*phpgEszN4Q6n_Rtd24zpGw.png \"sentences\")\n",
        "(Image from [this article](https://bansalh944.medium.com/text-generation-using-lstm-b6ced8629b03))\n",
        "\n",
        "We see that sequential data is everywhere! RNNs have accordingly bene applied to a wide variety of domains, including:\n",
        "\n",
        "- Natural Language Processing (NLP): translation, word prediction, sentiment analysis\n",
        "- Time-Series Analysis: financial predictions, weather/climate forecasting\n",
        "- Music Generation: e.g. composition\n",
        "- Robotics: e.g. path predictions\n",
        "\n",
        "How do RNNs work? Here's a helpful diagram:\n",
        "\n",
        "![RNN](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png \"rnn\")\n",
        "(Image from [this article](https://colah.github.io/posts/2015-08-Understanding-LSTMs/))\n",
        "\n",
        "In this diagram, $A$ represents the NN. Here, we take $x_t$ to represent the sequence of inputs ($x_0$, $x_1$, $x_2$,...,$x_N$), and $h_t$ its sequence of outputs ($h_0$, $h_1$, $h_2$,...,$h_N$). The sequential nature of the predictions is highlight by the rightward arrows; the prediction at each timestep is informed by the prediction at the previous timestep. Unfortunately, it has been shown that simple RNNs *fail to learn long-term dependencies*. This was the motivation for developing LSTMs.\n",
        "\n",
        "Okay, let's switch to a bit of coding.\n"
      ],
      "metadata": {
        "id": "MqBfwwg3kDrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# grab data\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "-E3OAoyMka0_",
        "outputId": "6bcf5f76-2198-40df-a4e2-5c03cde07aa7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fd6dba66aff9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1854\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m \u001b[0;31m# Enable CUDA Sanitizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymBool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m from torch._decomp import (\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0m_add_op_to_registry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0m_convert_out_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;31m# populate the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompositions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2996\u001b[0m \u001b[0mregister_rng_prims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2997\u001b[0;31m \u001b[0mregister_debug_prims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_prims/debug_prims.py\u001b[0m in \u001b[0;36mregister_debug_prims\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mload_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mload_tensor_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mLOAD_TENSOR_READER\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrand_strided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_custom_op/impl.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"factory\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BackendSelect\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_custom_op/impl.py\u001b[0m in \u001b[0;36m_register_impl\u001b[0;34m(self, kind, func, stacklevel)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;34mf\"{location}. This is not supported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             )\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{frame.filename}:{frame.lineno}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFuncAndLocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m             \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1625\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source code not available'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# Always map to the name the module knows itself by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             modulesbyfile[f] = modulesbyfile[\n\u001b[0;32m--> 878\u001b[0;31m                 os.path.realpath(f)] = module.__name__\n\u001b[0m\u001b[1;32m    879\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodulesbyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodulesbyfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/posixpath.py\u001b[0m in \u001b[0;36mrealpath\u001b[0;34m(filename, strict)\u001b[0m\n\u001b[1;32m    394\u001b[0m symbolic links encountered in the path.\"\"\"\n\u001b[1;32m    395\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_joinrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/posixpath.py\u001b[0m in \u001b[0;36m_joinrealpath\u001b[0;34m(path, rest, strict, seen)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mnewpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation"
      ],
      "metadata": {
        "id": "0MIJL6AZRLBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the last line, we grabed a CSV (comma-separated value) file called `airline-passengers.csv`. Let's use Pandas to explore the data."
      ],
      "metadata": {
        "id": "V86GylF4r2RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"airline-passengers.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "tC-c2ghnra2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that this is a time-series, counting the number of passengers (in units of 1,000) between Jan. 1949 and Dec. 1960, corresponding to 12 years and 144 observations. Let's plot the trend:"
      ],
      "metadata": {
        "id": "VaZLbY4esK8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(df.Passengers)\n",
        "plt.xlabel(\"Months Since 01/1949\")\n",
        "plt.ylabel(\"Airline Passengers / 1,000\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kqaIZNjirzTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What trends do you observe?"
      ],
      "metadata": {
        "id": "S9BF-m-PuRla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The upward trend may be difficult for the ML model to capture given the limited size of the dataset. We can simply remove it before training the algorithm, then add it back! Our goal will be to fit a quadratic to the data:\n",
        "\n",
        "`P(m) = x_0 + x_1 * m + x_2 * m^2`\n",
        "\n",
        "Where `P(m)` is the number of passengers in a given month `m`. Let's grab the regression coefficients:"
      ],
      "metadata": {
        "id": "wyj9QoI8QdWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(df)\n",
        "ones, xrange = np.ones(N), np.arange(N)\n",
        "X = np.stack((ones, xrange, xrange**2)).T\n",
        "y = df.Passengers.to_numpy().reshape(-1,1)\n",
        "beta = (np.linalg.inv(X.T @ X)@X.T@y)\n",
        "x0, x1, x2 = beta[0][0], beta[1][0], beta[2][0]\n",
        "x0, x1, x2"
      ],
      "metadata": {
        "id": "kZ883Os7Ako0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the corrected passengers data:"
      ],
      "metadata": {
        "id": "M5wpPvQURCle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passengers = df.Passengers\n",
        "plt.plot(passengers, label=\"Raw Data\")\n",
        "\n",
        "trend = x0 + xrange*x1 + xrange**2 * x2\n",
        "passengers_c = passengers - trend\n",
        "\n",
        "plt.plot(trend, \"r-\", label=\"Global Trend\")\n",
        "plt.plot(passengers_c, \"g--\", label=\"Corrected\")\n",
        "plt.xlabel(\"Months Since 01/1949\")\n",
        "plt.ylabel(\"Airline Passengers / 1,000\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LNi3ywgiBf3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Train/Test Sets"
      ],
      "metadata": {
        "id": "GmhrvNYJSpW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert everything to plain arrays\n",
        "passengers = passengers.values.astype(\"float32\").reshape(-1,1)\n",
        "passengers_c = passengers_c.values.astype(\"float32\").reshape(-1,1)\n",
        "passengers_c.shape"
      ],
      "metadata": {
        "id": "2kek8arZC-B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's turn this into an ML task. Given 30% of the time series, can we predict the remaining 70%? Fundamentally, that means we're doing regression.\n",
        "\n",
        "To train a model, we need to show it data in the time interval $[t-w, t-1]$, where $w$ is the \"sequence length\" or \"lookback\" size, and ask it to make predictions for the timestep $t$. To do this, we need to turn our training data into $(X,y)$ pairs,  $X,y\\in\\mathbb{R}^{w}$, where $X$ reprsents the inputs and $y$ represents the targets.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2SOsKDecu1gI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create windows [t-w,t-1] with corresponding truth labels [t]\n",
        "def sliding_windows(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)\n",
        "\n",
        "# scale the data in a nice way\n",
        "sc = MinMaxScaler()\n",
        "training_data = sc.fit_transform(passengers_c)\n",
        "\n",
        "# use a lookback window of size 4\n",
        "seq_length = 4\n",
        "x, y = sliding_windows(training_data, seq_length)\n",
        "\n",
        "train_size = int(len(y) * 0.30)\n",
        "test_size = len(y) - train_size\n",
        "\n",
        "data_x = torch.Tensor(np.array(x))\n",
        "data_y = torch.Tensor(np.array(y))\n",
        "\n",
        "train_x = torch.Tensor(np.array(x[0:train_size]))\n",
        "train_y = torch.Tensor(np.array(y[0:train_size]))\n",
        "\n",
        "test_x = torch.Tensor(np.array(x[train_size:len(x)]))\n",
        "test_y = torch.Tensor(np.array(y[train_size:len(y)]))\n",
        "\n",
        "print(training_data.shape)\n",
        "print(data_x.shape)\n",
        "print(data_y.shape)\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)"
      ],
      "metadata": {
        "id": "bPpafstXuwlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building an LSTM\n",
        "Now we're going to build a LSTM! Here's the PyTorch model:"
      ],
      "metadata": {
        "id": "NeSZ_2la3JRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Propagate input through LSTM\n",
        "        _, (h_out, _) = self.lstm(x)\n",
        "        h_out = h_out.view(-1, self.hidden_size)\n",
        "        out = self.fc(h_out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "lNupbk4E0YKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model has several components. The main workhorse is the **LSTM Module**: see the [PyTorch docs](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) for details of the implementation. Here's a diagram:\n",
        "\n",
        "![LSTM](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kT7TJdlJflJJSnEJ6XRKug.png \"lstm\")\\\n",
        "(Image from [this article](https://bansalh944.medium.com/text-generation-using-lstm-b6ced8629b03))\n",
        "\\\n",
        "\\\n",
        "This is a single LSTM \"block\" corresponding to the timestep $t$. There's a lot going on here, but here's the gist:\n",
        "\n",
        "- The LSTM block at timestep $t$ is fed by the input $x_t$ (# passengers), the output from the previous block $h_{t-1}$, and the memory from the previous block $c_{t-1}$.\n",
        "- The LSTM block at timestep $t$ is composed of several logical gates. These include an input gate, a forget gate, a cell gate, and an output gate. The full system of equations is\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "  i_t &= \\sigma(W_{ii} x_t + b_{ii} + W_{hi}h_{t-1} + b_{hi})\\ &\\rightarrow \\ \\ \\text{input gate} \\\\\n",
        "  f_t &= \\sigma(W_{if}x_t + b_{if} + W_{hf}h_{t-1} + b_{hf})\\ &\\rightarrow \\ \\ \\text{forget gate}\\\\\n",
        "  g_t &= \\text{tanh}(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{hg})\\ &\\rightarrow \\ \\ \\text{cell features}\\\\\n",
        "  o_t &= \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho})\\ &\\rightarrow \\ \\ \\text{output gate}\\\\\n",
        "  c_t &= f_t \\odot c_{t-1} + i_t \\odot g_t\\ &\\rightarrow \\ \\ \\text{cell state (memory)}\\\\\n",
        "  h_t &= o_t \\odot \\text{tanh}(c_t) \\ &\\rightarrow \\ \\ \\text{hidden state}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "In practice, the PyTorch module `nn.LSTM()` has inputs `input_size` corresponding to the dimension of $x_t$, `hidden_size` corresponding to the size of the outputs $h_{t}$, and `num_layers` corresponding to the number of \"stacked\" LSTM modules. Let's train an our model:"
      ],
      "metadata": {
        "id": "2qkn_eY03ZA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2000\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 1\n",
        "hidden_size = 16\n",
        "num_layers = 1\n",
        "\n",
        "num_classes = 1\n",
        "\n",
        "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
        "\n",
        "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = lstm(train_x)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # obtain the loss function\n",
        "    loss = criterion(outputs, train_y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n"
      ],
      "metadata": {
        "id": "iWoGxJQx4WRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm.eval()\n",
        "\n",
        "# predict on training and test data\n",
        "all_predict = lstm(data_x)\n",
        "\n",
        "data_predict = all_predict.data.numpy()\n",
        "data_y_plot = data_y.data.numpy()\n",
        "\n",
        "data_predict = sc.inverse_transform(data_predict).flatten()\n",
        "data_y_plot = sc.inverse_transform(data_y_plot).flatten()\n",
        "\n",
        "plt.axvline(x=train_size, c='r', linestyle='--', label='Train/Test Split')\n",
        "\n",
        "plt.plot(data_y_plot + trend[:-seq_length-1], label='Ground Truth')\n",
        "plt.plot(data_predict + trend[:-seq_length-1], label='predictions')\n",
        "plt.suptitle('Time-Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C1DbmBP7_azt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jLvxwOQnEoLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B5a4cG8WEZ-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}