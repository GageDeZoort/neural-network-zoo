{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Neural Networks**\n",
        "Gage DeZoort (3/25/24)"
      ],
      "metadata": {
        "id": "-RbxD4BGybG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks in PyTorch\n",
        "\n",
        "Phew, that was a lot of work. Let's train some NNs the easy way - using a modern deep learning (DL) library called PyTorch.\n"
      ],
      "metadata": {
        "id": "aPhFRtDFLscd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Reading Handwritten Digits\n",
        "\n",
        "As a working example, let's take a look at the MNIST handwritten digits dataset. Each sample is an image $x_i$ and a truth label $y_i\\in[1:9]$, corresponding to the number in the image. Some of the below code is adapted from the PyTorch Docs, e.g. the [Datasets and Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) page."
      ],
      "metadata": {
        "id": "1sorhc1LdR8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "FGMgIxA6c5n4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0d4904-2bd7-4753-e93f-6374e0807c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.0 Data Exploration"
      ],
      "metadata": {
        "id": "fDYhsIaahaVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grab the data and normalize it\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")"
      ],
      "metadata": {
        "id": "mhb0iqPDekoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88116909-a653-4e14-de12-57e0134753f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 162358824.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 38950383.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 46037500.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 20572925.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice, we've got some data - in the following cell we'll explore it a bit."
      ],
      "metadata": {
        "id": "qmyN-gCr1xLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print some dataset properties\n",
        "x0, y0 = train_data[0]\n",
        "print(f\"First image shape: {x0.shape}\")\n",
        "print(f\"First image label: {y0}\")\n",
        "print(f\"First image pixel mean: {torch.mean(x0):.3f}\")\n",
        "print(f\"First image pixel standard deviation: {torch.std(x0):.3f}\")\n",
        "\n",
        "# plot the first image\n",
        "fig = plt.figure(dpi=100, figsize=(4,4))\n",
        "plt.imshow(x0.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "fdFk-O8Afkdb",
        "outputId": "fc9277b2-3506-4627-9792-fcaa0f56d863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First image shape: torch.Size([1, 28, 28])\n",
            "First image label: 5\n",
            "First image pixel mean: 0.023\n",
            "First image pixel standard deviation: 1.014\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that each input is an image with $28\\times 28$ pixels, i.e. $x_i\\in\\mathbb{R}^{28\\times 28}$. Each of the pixels has a \"brightness\" value associated with it. This is because it represents a digtized image of a handwritten digit - each pixel's \"brightness\" corresponds to the presence of ink on the page. The truth labels just show you what number is in the image, in this case $y_0=5$. There are 60,000 train images and 10,000 test images. Let's plot a few more examples:"
      ],
      "metadata": {
        "id": "Lzwy3g-W149v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot several random examples\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
        "    img, label = train_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "JlNPeNnygLUi",
        "outputId": "7ac89cf6-d19e-4605-b91d-7bbc7e7eb4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAJ8CAYAAABgGKxrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAljUlEQVR4nO3dfbSVZZk/8L0VfBtMFNQMMGcUppkkLSxIsMbpZSp0MFDRTJAitVETtXyZJodcNRKpVA7pmMzk4MtgwGQZapHLlUtFY0zNmMp0QNHEGRXCF0A9+/fH7zfrN2P3teHh7LPPYV+fz5/Xda7nuTme55yvz1r3veuNRqNRAwCg423X2wsAAKA9BD8AgCQEPwCAJAQ/AIAkBD8AgCQEPwCAJAQ/AIAkBD8AgCQEPwCAJPpt6RfW6/WeXAf0ir74wTWeNTqRZw3aY3PPmjd+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASfTr7QXQ+fr371+sX3nlleHMxIkTi/UjjjginLnrrruqLYwUfvKTn4S9sWPHFuuHH374Vl0PoK/zxg8AIAnBDwAgCcEPACAJwQ8AIAnBDwAgCcEPACAJx7nQ4z7xiU8U69OmTat8reOOOy7sOc6FkkajUbm3aNGicObd7353sf6b3/ym2sKgTXbeeeewN2LEiGL91ltvDWf22muvYn3q1KnhzDPPPFOsv/e97w1nurq6wl5VCxcuDHsPP/xwsf7aa6+17P59iTd+AABJCH4AAEkIfgAASQh+AABJCH4AAEnY1dsHvfWtby3WDzjggHDmpptu6qnlbJGDDz447E2ZMqXy9davX1+sz507t/K1oKo99tgj7O20005tXAlsuf79+xfr3//+98OZP/uzP6t8n2g3/Le//e3K16rX62Fv3bp1xfqLL74YzgwcOLBYv+CCC8KZL33pS8X6zJkzw5ltmTd+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASTjOpZdceOGFYe+8884r1pt90PZVV11VrD/yyCPhzA9+8INi/WMf+1g4M3LkyGL9Qx/6UDiz4447Fut33XVXOHP00UcX62vWrAlnADKLjgLbmiNbtsZ//Md/hL3Zs2cX66+88ko4s2zZsmL9l7/8ZTizYMGCYn3SpEnhzKhRo8JeJ/LGDwAgCcEPACAJwQ8AIAnBDwAgCcEPACAJu3p7WPQhz6effno402z3buTkk0+uPPPVr3618kzkmWeeCXsXX3xxsT5//vxw5rnnnuv2mgAyWblyZbG+ePHicKbRaBTr3/nOdyrf/+abbw57GzZsqHy9SHRSRK1Wqw0cOLBl9+lU3vgBACQh+AEAJCH4AQAkIfgBACQh+AEAJCH4AQAk4TiXFvj+978f9saPH1/5eg899FCxfvnll4czJ510UuX7bI0lS5YU64sWLQpnfv3rX/fUcgD4f9auXVusH3vsse1dSA8bNmxY2Hvf+95X+XqrV6/uznK2Od74AQAkIfgBACQh+AEAJCH4AQAkIfgBACRhV+/rDBo0KOzNmjWrWN+anbu/+93vwt65555brP/whz8MZ+bNm1d5DQCwrdl///1ber3rrruupdfr67zxAwBIQvADAEhC8AMASELwAwBIQvADAEhC8AMASCLtcS777LNPsX711VeHMx/+8Idbdv/LL7887O28887F+sEHHxzOPPDAA91cEQD0HePGjSvW58+fX/laP/vZz8Jetr+f3vgBACQh+AEAJCH4AQAkIfgBACQh+AEAJNHRu3r79Yv/eeeee26x3sqdu818/vOfrzyzYcOGsPfSSy8V69dcc004c84551ReAwC0Sv/+/cPehRdeWKzvsccele9z2WWXhb0XXnih8vW2Zd74AQAkIfgBACQh+AEAJCH4AQAkIfgBACQh+AEAJNHRx7l8/OMfD3tnnnlmG1fy+1atWhX21q1bV6y/7W1vC2d22mmnYn369OnhzNe//vVi/fHHHw9nAKBVZsyYEfb+/M//vPL1vv3tbxfrixcvrnytTuWNHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASHb2rd++996488/LLL4e9BQsWFOvNdgvdfPPNldcQGTFiRNibN29esT527Nhw5hvf+EaxftRRR1VaF/Rl9Xq9cm+77fw/MbTDrFmzwl6j0SjWn3/++XDma1/7WrG+cePGSuvqZH67AQAkIfgBACQh+AEAJCH4AQAkIfgBACQh+AEAJNHRx7l861vfCnvf/e53i/VmW75XrlzZzRV1z69//euw96tf/apYb3acS7RVHjpJs5/zqNfV1dVTy4GUZs6cWaw3Ozopeg6bHaH28MMPV1pXRt74AQAkIfgBACQh+AEAJCH4AQAkIfgBACTREbt6Dz744GL9gx/8YDgze/bsHlpN7/jABz7Q20uAjrF06dKwt3r16jauBLYd733ve8PeeeedV6w320H/1FNPFetz5syptjD+F2/8AACSEPwAAJIQ/AAAkhD8AACSEPwAAJIQ/AAAkuiI41xOP/30Yv2//uu/2rySnnXaaaeFvWHDhhXrr776ajhz1VVXdXtN0Il+85vfhL21a9e2byGwDTn//PPDXv/+/Yv1RqMRzvz1X/91sf7LX/6y2sL4X7zxAwBIQvADAEhC8AMASELwAwBIQvADAEiiI3b1dpoPfOADxfqXv/zlytdqtgPxlltuqXw9yODhhx/u7SVAn/X1r3+9WB83blzla1166aVhb/78+ZWvx+Z54wcAkITgBwCQhOAHAJCE4AcAkITgBwCQhOAHAJBERxznUq/Xe3sJlQ0aNCjsRce2vOENbwhnHn300WL9+OOPr7Yw6DBXXHFF2Bs7dmwbVwLbjmZ/O6ZNm1as77zzzuHME088Uayfd9551RZGt3njBwCQhOAHAJCE4AcAkITgBwCQhOAHAJBER+zqbTQaxfoJJ5wQzlx77bXFeqs/nH2fffYp1hcuXBjOHHLIIcX6hg0bwplPf/rTxfry5cubrA4639Y80wceeGAPrAT6njFjxhTrV155ZTizyy67VL7PRRddVHmGnuGNHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASgh8AQBIdcZxLZMiQIWHvW9/6VrH+N3/zN+HMxo0bi/UJEyaEM6ecckqxPmDAgHAmMmvWrLC3dOnSytcDILfdd9+9WP+DP/iDyte64YYbwt4///M/V74ePcMbPwCAJAQ/AIAkBD8AgCQEPwCAJAQ/AIAkOmJX74wZM4r1TZs2hTOnnnpqsX7rrbeGM11dXcX6DjvsEM40Go1iffXq1eHMpz71qWL99ttvD2eAsnPOOafyzFNPPdUDK4G+Jzp5Ymt8+ctfDnuvvfZay+5D93jjBwCQhOAHAJCE4AcAkITgBwCQhOAHAJCE4AcAkERHHOfywgsvFOtnnnlmOHPnnXcW6xMnTgxnJk2aVKyvWbMmnLn44ouL9fnz54czzz33XNgDqrnvvvvC3oknnlisNzuWAjrJ7rvvXnnmoYceKtabHVNG3+GNHwBAEoIfAEASgh8AQBKCHwBAEoIfAEAS9Uaj0diiL6zXe3ot0HZb+OPfVp41OpFnrW/6y7/8y2J98eLF4cy1115brE+bNi2c6Yv//TvV5r7X3vgBACQh+AEAJCH4AQAkIfgBACQh+AEAJCH4AQAk4TgXUuuLRwx41uhEnjVoD8e5AABQq9UEPwCANAQ/AIAkBD8AgCQEPwCAJAQ/AIAkBD8AgCQEPwCAJAQ/AIAkBD8AgCQEPwCAJAQ/AIAk6o2++MnZAAC0nDd+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEn029IvrNfrPbkO6BWNRqO3l/B7PGt0Is8atMfmnjVv/AAAkhD8AACSEPwAAJIQ/AAAkhD8AACSEPwAAJIQ/AAAkhD8AACSEPwAAJIQ/AAAkhD8AACSEPwAAJIQ/AAAkhD8AACSEPwAAJIQ/AAAkhD8AACSEPwAAJIQ/AAAkhD8AACSEPwAAJIQ/AAAkhD8AACSEPwAAJIQ/AAAkujX2wsA2FL9+/cPe+9617tadp96vR72Go1GsT5r1qxwZuzYsZXXcPHFFxfr3/ve98KZe++9t/J9gFy88QMASELwAwBIQvADAEhC8AMASELwAwBIot6Itqi9/gub7HLbFh111FHF+siRI8OZiy66qPJ9lixZUqwPHz48nLn66quL9fXr14czV1xxRbWFUavV4h2avanTnrWt8eEPf7hYHz16dDjzhS98oWX335pdve3y4osvhr2pU6cW6//6r//aU8vZYr39fSvxrLXWfvvtF/ZOPvnkYv2CCy4IZ7bmZ+bAAw8s1lesWFH5WtuqzX3fvPEDAEhC8AMASELwAwBIQvADAEhC8AMASELwAwBIoqOPc9lzzz3D3i233FKsv+Md7+ip5XRbV1dX2Hv++eeL9aVLl4YzU6ZMKdZfeeWVagvbhjlioucNHTq0WP/7v//7cOaggw4q1vfdd9+WrGlzttsu/n/iZs9hb7vpppuK9YkTJ7Z5Jb/Ps7Ztec973hP2Pv/5zxfrzf5+7rHHHsV6q49O+rd/+7difezYseFMp/3Nc5wLAAC1Wk3wAwBIQ/ADAEhC8AMASELwAwBIol9vL6An7b///mGvL+/ejTTbaTho0KBiffLkyeHMxo0bi/Vmuy2XL18e9qBkwIABxfqRRx7Z0vusX7++WH/yyScrX6tdu3oHDhwY9t74xjcW66+++mo4szX/VnKbPXt2sX7KKaeEM9EzvTWeffbZsPeTn/ykWG/293vUqFHF+jvf+c5w5u677w57ncgbPwCAJAQ/AIAkBD8AgCQEPwCAJAQ/AIAkBD8AgCQ6+jiXFStWhL158+YV69GHw9dqtdohhxzS7TX9t8cffzzsteuD6KdMmVKsDxs2LJyZMGFCsf7CCy+0ZE3QzMKFC8NedPTD3Llze2o53fbJT34y7F111VXF+tq1a8OZM844o7tLogO9//3vD3uf/exni/VGoxHOREcnNTs+LDoKrNnxRNF9rr322nAm+vu52267hTPZeOMHAJCE4AcAkITgBwCQhOAHAJCE4AcAkERH7+r93e9+F/Y+9alPFev9+/cPZ4444ohur+m/PfbYY2HvxhtvLNaHDx/esvs38653vSvs7b///sX6gw8+2FPLoUPdeeedYe+aa64p1hcvXhzOrFu3rttrgm3ZwIEDi/VW72yPdgLfdtttLb1PZPbs2WEvOnlixx137KnlbHO88QMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEii3mj2Scz/8wvr9Z5eS0faddddi/VLL700nJk+fXpPLWeLLFq0KOwdc8wxbVxJz9vCH/+26rRnbYcddijWd99993BmzZo1PbWcbttll10q1Wu1Wm3JkiXF+tChQyvf56ijjgpn7rjjjrDX2zxrPe8tb3lLsb5ixYpwJvoenH322eHMnDlzqi2sj9t7772L9b78e6iZzT1r3vgBACQh+AEAJCH4AQAkIfgBACQh+AEAJNGvtxfQCb74xS+GvRkzZhTr0W7fvqBdH7RNDps2bSrW+/KOuUGDBoW9Sy65pFifMmVK5fusWrUq7J144onFel/euUvvmjRpUrHebJfnv/zLvxTrc+fObcma+oqZM2eGvQkTJhTr48ePD2eeeuqp7i6p13jjBwCQhOAHAJCE4AcAkITgBwCQhOAHAJCE4AcAkITjXF4n+kD5Wq1W++53v1usf+hDH+qh1fSsqVOnFuvXXnttm1cCPafZkQzvec97ivWhQ4eGM8cdd1zlNURHPt17773hzI9//OPK96Hz7bPPPmFv8uTJla/3ox/9qFiPjmHq6y688MJi/bTTTgtnouObzjjjjHDmggsuqLawPsQbPwCAJAQ/AIAkBD8AgCQEPwCAJAQ/AIAk6o1mn978P7+wXu/ptfQJb3jDG8Le2rVr27eQiqLdgUcffXQ489vf/rZY7+rqasmatgVb+OPfVlmetVYbN25csX7DDTeEM29605uK9Wb/DaKfmfPPPz+cmTNnTrH+6quvhjOdxrPWGhMmTAh7ixcvrny97bffvjvL6bZddtkl7A0fPrxYP++888KZY445pljfbrv4PVf0c7B69epwZt999w17vW1zz5o3fgAASQh+AABJCH4AAEkIfgAASQh+AABJCH4AAEn06+0F8PvWr19frH/mM58JZ5YsWVKs/+d//mdL1gTtdMABBxTrt99+ezgzdOjQyvf5+c9/Xqzfc8894cypp55a+T6Q3RFHHFGsT506NZyZOHFiTy1niyxdurRX799TvPEDAEhC8AMASELwAwBIQvADAEhC8AMASMKu3td56aWXwt6ll15arB933HHhzJAhQ7q9pv925JFHhr0HHnigWLerl942aNCgYv2Tn/xkODNp0qRivdnzFH0w+R133BHOfOITnyjWV61aFc5Ab3r22WfD3lNPPVWsN3tuxo4dW3kN++67b7F+/vnnhzMjR44s1uv1ejgTPdOtFp2kcf3117fl/u3mjR8AQBKCHwBAEoIfAEASgh8AQBKCHwBAEoIfAEAS9cYW7pdutuU6u2bHUnzlK18p1vfYY4+WrqGrq6tYv/HGG8OZaN0vv/xyS9a0LWjXcQFVdNqz9pa3vKVY/8UvflH5Wn/1V38V9qKjLFasWBHOPProo5XXwNbxrPW8j3/848X6NddcE85E34N2/ffqC8e5nH766cX6FVdc0Zb7t9rmvm/e+AEAJCH4AQAkIfgBACQh+AEAJCH4AQAkYVdvD/vjP/7jYv2WW24JZ6IP1O7fv39L1vTf/uEf/qFYnzlzZjizZs2alq6ht9lpWM2gQYOK9T333DOcufXWW4v1XXfdNZx5+umni/Xx48eHMytXrgx79D7PWs8bOnRosX7TTTeFM29/+9uL9U7b1Ttv3rywd/LJJ7fsPn2BXb0AANRqNcEPACANwQ8AIAnBDwAgCcEPACAJwQ8AIAnHufRBBx98cLF+//33t+X+ixYtCnvHHHNMW9bQLo6YqObcc88t1i+++OJwZu3atcX62WefHc40+1B5tk2etd6z0047hb0FCxYU66NHjw5nouObHnnkkXDmwQcfLNab/U3Zmp+ZTZs2Fevvfve7w5kHHnig8n36Mse5AABQq9UEPwCANAQ/AIAkBD8AgCQEPwCAJPr19gKyaraT6W1ve1sbVwL/2wEHHBD2Jk2aVPl6Tz/9dLFu5y60x4YNG8LehAkTivUhQ4aEM29+85uL9VWrVoUzp59+ethrpc985jPFeqft3O0Ob/wAAJIQ/AAAkhD8AACSEPwAAJIQ/AAAkhD8AACScJzL64wZMybsXXfddS27T7Ot8jvssEPL7gNV7b333mHvkEMOqXy97bffvlgfPHhw5Wu1y8iRI8PeuHHjivXoiItarVYbO3Zst9e0Je68885i/cwzzwxnXn755Z5aDtuwJ598snLvoIMOCmdOOumkYr1er4czr7zySrG+cOHCcGb+/Plhj//LGz8AgCQEPwCAJAQ/AIAkBD8AgCQEPwCAJOzqfZ0999wz7P3hH/5hG1fSe5rtaNx3332L9ccff7ynlkObHXbYYS293vDhw4v1NWvWtPQ+rdRsp2Gj0WjjSqoZMWJEsd6vX/yr/rOf/Wyx/txzz7VkTXSeHXfcsVifNWtWOLPXXnsV682ep6effrpYP+GEE5qsjs3xxg8AIAnBDwAgCcEPACAJwQ8AIAnBDwAgCcEPACAJx7m8zjPPPNPbS2ib559/vlg/44wzwhnHtnS+v/u7vwt7ffkoE2KDBw8OezvvvHMbV0In+OpXv1qsf/CDH6x8rWeffTbsTZ48ufL12Dxv/AAAkhD8AACSEPwAAJIQ/AAAkhD8AACSsKv3dX72s5+FvQULFhTr48ePD2cGDBjQ7TVtiRdeeKFYv/nmm8OZb3zjG8X6smXLWrImtk2f/vSnw943v/nNNq6kc3zkIx8p1tetW9eW+z/xxBNh78knn2zLGugcw4YNa9m15s6dG/b8LeoZ3vgBACQh+AEAJCH4AQAkIfgBACQh+AEAJCH4AQAkUW9s4aeu1+v1nl7LNmvUqFFh7/DDDy/WzzrrrHAmOoLlkUceCWduv/32Yv3+++8PZ6jVtvDHv608a3Qiz1rnmD17drF+zjnnhDOXXXZZsf65z32uJWvi/9vcs+aNHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASdvWSmp2G0B6eNWgPu3oBAKjVaoIfAEAagh8AQBKCHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASgh8AQBKCHwBAEvVGo9Ho7UUAANDzvPEDAEhC8AMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEhC8AMASKLfln5hvV7vyXVAr2g0Gr29hN/jWaMTedagPTb3rHnjBwCQhOAHAJCE4AcAkITgBwCQhOAHAJCE4AcAkITgBwCQhOAHAJCE4AcAkITgBwCQhOAHAJCE4AcAkITgBwCQhOAHAJCE4AcAkITgBwCQhOAHAJCE4AcAkITgBwCQhOAHAJCE4AcAkITgBwCQhOAHAJCE4AcAkES/3l5AVqNGjQp7y5cvL9YbjUY4c9pppxXr//RP/xTObNy4sfJ9AIBtlzd+AABJCH4AAEkIfgAASQh+AABJCH4AAEnUG1u4hbNer/f0WrZZzb43J598crF+9tlnhzMHHHBA5TU88sgjxfpzzz0XzjzwwAPF+mWXXRbOrFmzplhfv359vLg+rC/uYPas9b5p06aFvXnz5hXrZ5xxRjgzd+7cbq9pW+dZg/bY3LPmjR8AQBKCHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASjnNpgTe/+c1h77HHHmvjSnreD37wg2L9xBNPDGfWrVvXU8vpNkdMULJo0aKwd9RRRxXrS5YsqTzz2muvVVnWNs2z1jcde+yxxfqZZ54Zzhx66KHFeldXVziz3Xbl90yXXHJJOPPTn/60WG/2s3TWWWcV69G/s1ar1VavXh32tkWOcwEAoFarCX4AAGkIfgAASQh+AABJCH4AAEn06+0FdIIpU6b09hJqTz31VLH+85//PJwZPnx4sf5Hf/RH4cz48eOL9WuuuSacmTp1arHel3f7ksOBBx5YrH/0ox8NZ6Idcxs2bKg8A+0Q7XSt1eJdtc126Ea9ZjORGTNmhL1oJ/DW7B6+4YYbwpnDDjss7HUib/wAAJIQ/AAAkhD8AACSEPwAAJIQ/AAAkhD8AACScJxLBSNGjCjWp0+fXvlaK1asCHt/+qd/WqxfeeWV4cysWbOK9SeeeCKceeMb31isz5kzJ5yJPuj6yCOPDGeiY2OWL18ezkA7vO997yvW6/V6OBMdzbJkyZJwZmuOuYCSMWPGhL177rmnWN+a40+aiZ6PZtfq7ZlDDz00nIm+p8uWLQtntmXe+AEAJCH4AQAkIfgBACQh+AEAJCH4AQAkYVfv60yYMCHs/eM//mOxPnDgwHDmtttuK9bPOOOMcOYrX/lKsX799deHM81270aefvrpYv1LX/pSOBPt6m0m+hDwZt/rdevWVb4PtEq0c7eZn/70pz2wEvjfZsyYEfai3btbs6t8a3YCb6sz0ff0uOOOC2e2Zd74AQAkIfgBACQh+AEAJCH4AQAkIfgBACQh+AEAJOE4l9d5//vfH/aaHdsSueWWW4r1Rx99NJw555xzivWtOWJia/z7v/972Fu4cGGxfvTRR4czhx12WLE+ePDgcMZxLrTDiBEjKs+sWbOmWPczSytFR2cdc8wx4Ux0lEkzWzNTr9crX6tdM08++WSxfvfdd4cznXpsS8QbPwCAJAQ/AIAkBD8AgCQEPwCAJAQ/AIAk0u7qHTVqVLEe7aRqZtOmTWHv8ssvr3y9VatWVZ5ppWYfZv3aa69Vvt7GjRtbdi2oql+/+NfcRz7ykcrX+8UvflGsP/HEE5WvBZFoF2qz3amHHnposd7sd3qk2Uy0q7YvzER/w5ctWxbOZOONHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASgh8AQBJpj3OZPXt2sT548ODK11qyZEl3l7PNuPfee4v1yZMnhzM333xzsb5y5cpWLAmaanZky7777lv5es8++2x3lgNbZPXq1cX64sWLw5ntt9++WB89enQ4Ex2Z0ky9Xq98rVbOHH/88eGMY1s2zxs/AIAkBD8AgCQEPwCAJAQ/AIAkBD8AgCQ6elfvrrvuGvZ22223lt3noosuatm1+rpmu8OgL/roRz9aeebFF18Me5dddll3lgPdMmfOnLD3ne98p1hv9nv7xhtvLNa7urrCmWgnbrtmGo1GOMPmeeMHAJCE4AcAkITgBwCQhOAHAJCE4AcAkITgBwCQREcf5/Inf/InYe/tb3975eutXLmyWP/Vr35V+VqZXH/99b29BBIbNmxY5Zlnnnkm7N13333dWQ70mNWrV1eq12q12vbbb1+sn3XWWeHMpZdeWqxHx6/UarVavV5v2Ux0BE2tVquNHTu2WF+2bFk4k403fgAASQh+AABJCH4AAEkIfgAASQh+AABJdPSu3re+9a0tvd6SJUuK9Q0bNrT0Pr1twIABYW+//farfL1mO8qgVd70pjcV6yNGjAhnol2DUR2ymDNnTti75JJLivWurq5wJtq92+qZGTNmFOvHHXdcOJONN34AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJdMRxLgMHDizWzzzzzJbeZ/ny5S29Xl/1hS98IeyNHj26WL/rrrvCmQcffLDba4LNOeigg4r1IUOGhDONRqNY/973vteSNUEnio47io5faefMscceW6wvXLgwnGnW60Te+AEAJCH4AQAkIfgBACQh+AEAJCH4AQAk0RG7egcPHlysjxw5sqX3uf3221t6vd42YMCAYv3www+vfK1NmzaFvVdeeaXy9aCkf//+Ye/8889v2X1uvvnmll0LOk20G76rqyuciXbitmsmWnNG3vgBACQh+AEAJCH4AQAkIfgBACQh+AEAJCH4AQAk0RHHubB1fvSjHxXro0aNCmeio1kcf0E77LjjjmFv3Lhxla/30ksvFetLly6tfC3oJAsWLAh79Xq9WI+OUukLM1E9I2/8AACSEPwAAJIQ/AAAkhD8AACSEPwAAJLoiF29GzduLNbXrVsXzuy22249tZw+5aSTTgp773znOytf74477ijWv/a1r1W+FvS2q6++ureXAH1So9Go3Ovq6gpnop247Zpp9u/Jxhs/AIAkBD8AgCQEPwCAJAQ/AIAkBD8AgCQEPwCAJDriOJcnnniiWP/xj38czkycOLGnltMrpk+fXqxffvnl4Uz0odXLly8PZ6ZNm1ZtYdBCkydP7u0lQArR34dmvegolb4wM2bMmHBm0aJFYa8TeeMHAJCE4AcAkITgBwCQhOAHAJCE4AcAkERH7OqNzJ8/P+xtza7emTNnFuunnHJKOPPqq68W64ccckg4s99++xXrH/vYx8KZv/iLvyjWd9hhh8pr+9u//dtw5re//W3Yg5621157tfR69913X0uvB52i0WhU7nV1dYUz0U7cds3MmDEjnPnc5z4X9jqRN34AAEkIfgAASQh+AABJCH4AAEkIfgAASQh+AABJdPRxLj/84Q/D3r333lusjx49Opw56aSTivX+/fuHM/fff3+x/sUvfjGcGTBgQNhrpenTpxfrt956a1vuD73tnnvu6e0lQJ9Ur9cr96KjVPrCzPHHHx/OZOONHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASHb2rd8OGDWHv1FNPLdab7fx5xzveUayfcMIJ4cw+++xTrH/zm98MZ4YMGRL2IrfddluxvmTJknBm7dq1le8DvWnlypWVZ+6+++6wt2bNmm6sBjrXnDlzwt7RRx9drHd1dYUz0U7cds00Go1wJhtv/AAAkhD8AACSEPwAAJIQ/AAAkhD8AACSEPwAAJLo6ONcmnnooYcq1YHet3jx4rB33XXXFeuPPfZYOPPyyy93e03QiZYtWxb2xo4dW6wvWLAgnBk2bFixHh2/UqvVavV6vfLMk08+WamekTd+AABJCH4AAEkIfgAASQh+AABJCH4AAEnUG1v4ycXR7hrYlvXFD+72rNGJPGudb8yYMWFv0qRJxfqMGTPCmWj37qWXXhrORDv/m+1S7jSbe9a88QMASELwAwBIQvADAEhC8AMASELwAwBIQvADAEjCcS6k5ogJaA/PGrSH41wAAKjVaoIfAEAagh8AQBKCHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASgh8AQBKCHwBAEoIfAEASgh8AQBL1Rl/85GwAAFrOGz8AgCQEPwCAJAQ/AIAkBD8AgCQEPwCAJAQ/AIAkBD8AgCQEPwCAJAQ/AIAk/g+jSbAXFyMf6AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1 Data Preparation\n",
        "\n",
        "Now that we've taken some time to look at the data, let's use the default `MNIST DataLoaders` provided by `PyTorch`. We'll apply several transformations to the images. First, we'll ensure that they're stored as torch `tensor` objects, which you can think of as high-dimensional matrices that have gradients attached to them. Next, we'll normalize the data to have mean 0 and standard deviation 1 using the constants provided by `PyTorch`. Finally, we'll *flatten* the images into 28x28=784 dimensional arrays so that we can pass them into the NN."
      ],
      "metadata": {
        "id": "uNIqf0RHhgSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "82aX3KiphETj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's flatten and normalize the data\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "    transforms.Lambda(lambda x: torch.flatten(x))\n",
        "])\n",
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")"
      ],
      "metadata": {
        "id": "DBiAnYtEiegc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the first image in the train set and check that it is now a vector of size $784$:"
      ],
      "metadata": {
        "id": "XXEnQdEh3NO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the dimensions right - the original image was [1, 28, 28])\n",
        "x0, y0 = train_data[0]\n",
        "print(f\"Image Shape: {x0.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_aDeM-4k1GY",
        "outputId": "b747b1d8-dbee-4b7a-ddac-44fa16becd09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Shape: torch.Size([784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our datasets in hand, `PyTorch` provides `DataLoader` classes designed to sample *batches* of data. Batching allows us to make predictions on several inputs at once before computing the gradients and using them to update the model. In this case, we pull a batch size of 128 images from the train set:"
      ],
      "metadata": {
        "id": "t3wOGK0V3V0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's build some data loaders\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "JQ5TzBzAk7OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2 Training an NN\n",
        "We've got our data, so now we need to build a model. We'll use the $ReLU(z)=\\mathrm{max}(0,z)$ activation function and 2 hidden layers of size $128$. To do so, we're going to use the following `PyTorch` objects belonging to the `torch.nn` class:\n",
        "\n",
        "- `Linear` creates weight and bias matrices populated with learnable parameters.\n",
        "- `ReLU` implements the ReLU activation function.\n",
        "- `Sequential` is a container for modules like `Linear` and `ReLU`. Once you have a `Sequential` object, it will apply all its modules in sequence, producing an output for you.\n",
        "\n",
        "\n",
        "We're going to use these 3 ingredients in the cells below to create the following NN architecture:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{Input}:&\\qquad x_0\\in\\mathbb{R}^{784}\\\\\n",
        "\\text{1st Preactivations}:&\\qquad  z_1 = W_1x_0 + b_1\\\\\n",
        "\\text{1st Hidden Layer}:&\\qquad \\sigma_1 = \\mathrm{ReLU}(z_1)\\\\\n",
        "\\text{2nd Preactivations}:&\\qquad z_2 = W_2\\sigma_1+ b_2\\\\\n",
        "\\text{2nd Hidden Layer}:&\\qquad \\sigma_2=\\mathrm{ReLU}(z_2)\\\\\n",
        "\\text{Output}:&\\qquad W_3\\sigma_2 + b_3\\in\\mathbb{R}^{10}\n",
        "\\end{align}\n",
        "\n",
        "Our network is a function $f:\\mathbb{R}^{784}\\rightarrow\\mathbb{R}^{10}$, i.e. its outputs will correspond to the probabilities that the 784 dimensional input is each digit between 0 and 9. Note that there's no output activation function because `PyTorch` will apply it for you."
      ],
      "metadata": {
        "id": "BFN2bSnmluYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import time\n",
        "from torch.nn import Sequential, Linear, ReLU, CrossEntropyLoss\n",
        "from torch.optim import SGD"
      ],
      "metadata": {
        "id": "VHPOiZNgls2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(\n",
        "    Linear(784, 128), # maps input_dim 784 to hidden_dim 128\n",
        "    ReLU(), # 1st hidden layer has dimension 128\n",
        "    Linear(128, 128), # maps hidden_dim 128 to hidden_dim 128\n",
        "    ReLU(),  # 2nd hidden layer has dim 128\n",
        "    Linear(128, 10) # maps hidden_dim 128 to output_dim 10\n",
        ")"
      ],
      "metadata": {
        "id": "ptyX1xbKlRcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll ooptimize a cross entropy loss since we've got another multi-class classification problem."
      ],
      "metadata": {
        "id": "9cWJaQR07AkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "CO6vutPHpK-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previously, we applied gradient descent to train our network. We're going to do something similar here by applying *stochastic gradient descent* (SGD). Here, stochastic means that instead of calculating full gradients (which is expensive), we're going to estimate the gradients by randomly selecting subsets of data. The learning rate, or `lr` below, controls the speed of learning and needs to be carefully tuned in practice. We've also introduced another hyperparameter called `momentum`. In a nutshell, momentum means that the minimization experiences inertia when performing gradient descent - if a direction is consistently favorable, the optimization will begin to build speed in that direction. This is generally a good thing to do in practice, as you can \"run past\" noisy fluctuations or flat regions of the loss landscape."
      ],
      "metadata": {
        "id": "9emNLOTu8Bhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = SGD(model.parameters(), lr=0.005, momentum=0.8)"
      ],
      "metadata": {
        "id": "ufHfm-aPpQgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to train our model. To do so, we're going to run a standard `PyTorch` train step repeatedly over all the training data. In practice, you'll usually grab a similar train function from the `PyTorch` documentation pages and then adapt it to your own needs. The train step has several key ingredients, which are heavily commented in the cell below."
      ],
      "metadata": {
        "id": "8DvcbQSt9XYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, train_loader, optimizer, loss_fn):\n",
        "  # track the total loss and the number N of images processed\n",
        "  total_loss, N = 0, 0\n",
        "\n",
        "  # set the model in train mode, which tells PyTorch to track gradients\n",
        "  model.train()\n",
        "\n",
        "  # loop over batches of images (batch_size x 784) and labels (784)\n",
        "  t0 = time.time()\n",
        "  for data in train_loader:\n",
        "\n",
        "    # unpack the data in the batch\n",
        "    (images, labels) = data\n",
        "\n",
        "    # zero out any gradients calculated during the last batch\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # use the model to predict labels for each image\n",
        "    y_pred = model(images)\n",
        "\n",
        "    # calculate the cross entropy loss between the prediction and truth\n",
        "    loss = loss_fn(y_pred, labels)\n",
        "\n",
        "    # compute the gradients of the loss function\n",
        "    loss.backward()\n",
        "\n",
        "    # use the gradients to update the model's learnable parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # accumulate some statistics\n",
        "    total_loss += loss.item()\n",
        "    N+=len(labels)\n",
        "\n",
        "  return total_loss/N, time.time()-t0"
      ],
      "metadata": {
        "id": "b3ZLChzMnkpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our train step in hand, now we just need to run a training loop over several epochs:"
      ],
      "metadata": {
        "id": "SmCmBgecAQ1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training sequence\n",
        "n_epochs = 10\n",
        "for epoch in range(n_epochs):\n",
        "  epoch_loss, epoch_time = train_step(model, train_loader, optimizer, loss_fn)\n",
        "  print(f\"Epoch {epoch}: loss={epoch_loss:.4f}, time={epoch_time:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKfdMgCmAXT1",
        "outputId": "4170afa1-4da3-4411-a8b9-d28d883a66a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss=0.0057, time=13.8593\n",
            "Epoch 1: loss=0.0022, time=14.2437\n",
            "Epoch 2: loss=0.0018, time=13.3912\n",
            "Epoch 3: loss=0.0015, time=13.4511\n",
            "Epoch 4: loss=0.0013, time=13.4039\n",
            "Epoch 5: loss=0.0012, time=13.5913\n",
            "Epoch 6: loss=0.0010, time=13.4915\n",
            "Epoch 7: loss=0.0009, time=13.7718\n",
            "Epoch 8: loss=0.0008, time=13.4092\n",
            "Epoch 9: loss=0.0008, time=13.9780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should notice tha the loss steadiliy decreases from epoch to epoch. Each epoch should take about 10 seconds. If this feels slow, don't worry - we'll speed it up in subsequent cells. Now that our model has been trained, it's time to evaluate its performance. Ideally, we hope that it has learned to recognize images from the train set in a general way, i.e. that it hasn't just memorized the train data (this is called overfitting). To test the model's *generalization*, we will apply it to the sample of test data, which it has so far never seen. In doing so, we need to write a new test step. This will look similar to the train step, except now we're *not* going to calculate gradients or update the model's learnable parameters. We encode this explicitly by writing `model.eval()` and `with torch.no_grad()`."
      ],
      "metadata": {
        "id": "6XZulSVUA8Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model, test_loader, loss_fn):\n",
        "  # statistics to accumulate\n",
        "  total_loss, total_correct, N = 0, 0, 0\n",
        "\n",
        "  # tell torch not to track gradients or update the model\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # loop over all batches in the test data\n",
        "    for data in enumerate(test_loader):\n",
        "\n",
        "      # unpack the batch of data\n",
        "      idx, (images, labels) = data\n",
        "\n",
        "      # calculate the model's prediction\n",
        "      y_pred = model(images)\n",
        "\n",
        "      # compute the loss and store relevant statistics\n",
        "      loss = loss_fn(y_pred, labels)\n",
        "      total_loss += loss.item()\n",
        "      total_correct += sum(y_pred.argmax(1)==labels)\n",
        "      N+=len(labels)\n",
        "\n",
        "  return total_loss/N, total_correct/N\n",
        "\n",
        "# evaluate the model\n",
        "loss, acc = test_step(model, test_loader, loss_fn)\n",
        "print(\"Test Set Performance:\")\n",
        "print(f\"Average Loss: {loss:.3f}\")\n",
        "print(f\"Classification Accuracy: {acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3TDkLkIp7b3",
        "outputId": "e43cae26-434d-4d54-a5a6-4f9fda00c5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Performance:\n",
            "Average Loss: 0.001\n",
            "Classification Accuracy: 0.969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hey, 97% is pretty good considering we just treated the images as vectors, effectively disregarding any local spatial information inside of them. More complicated architectures like convolutional neural networks (CNNs) can leverage this localized information to make even better predictions on MNIST."
      ],
      "metadata": {
        "id": "E4fr2bx-CSo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Faster Training"
      ],
      "metadata": {
        "id": "Kryb6_EF8y5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "\n",
        "class FastMNIST(MNIST): # build our new class on top of the old one\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        # flatten, re-scale, normalize the data\n",
        "        self.data = self.data.unsqueeze(1).float().div(255)\n",
        "        self.data = self.data.sub_(0.1307).div_(0.3081)\n",
        "        self.data = self.data.view(len(self.data), 28*28)\n",
        "\n",
        "        # load all the images and labels onto the GPU in advance\n",
        "        self.data, self.targets = self.data.to(device), self.targets.to(device)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        return (img, target)\n",
        "\n",
        "# create our new FastMNIST dataset\n",
        "train_data = FastMNIST(\"data\", train=True, download=True)\n",
        "test_data = FastMNIST(\"data\", train=False, download=True)\n",
        "\n",
        "# this works just like our last dataset except everything is now on a GPU\n",
        "train_loader = DataLoader(train_data, batch_size=128, num_workers=0, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=128, num_workers=0, shuffle=False)"
      ],
      "metadata": {
        "id": "mHn5_VgYERGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd00755-6f7b-4798-eb98-0a7bd3fc9235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/FastMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 148984846.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FastMNIST/raw/train-images-idx3-ubyte.gz to data/FastMNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/FastMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 61179643.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FastMNIST/raw/train-labels-idx1-ubyte.gz to data/FastMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/FastMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 49944330.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FastMNIST/raw/t10k-images-idx3-ubyte.gz to data/FastMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/FastMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4974028.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FastMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FastMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start our training procedure over. Above, we have code for the `train_step` and `test_step`, so let's define a new model and train it again by minimizing `CrossEntropyLoss` with the `SGD` optimization algorithm. This time, you'll see that it trains *much* faster with each epoch taking around 1 second."
      ],
      "metadata": {
        "id": "y_G6unj6DRN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(\n",
        "    Linear(784, 128),\n",
        "    ReLU(), # hidden layer has dimension 32\n",
        "    Linear(128, 128),\n",
        "    ReLU(),\n",
        "    Linear(128, 10)\n",
        ").to(device)\n",
        "\n",
        "loss_fn = CrossEntropyLoss()\n",
        "optimizer = SGD(model.parameters(), lr=0.005, momentum=0.8)\n",
        "\n",
        "# training sequence\n",
        "n_epochs = 10\n",
        "for epoch in range(n_epochs):\n",
        "  epoch_loss, epoch_time = train_step(model, train_loader, optimizer, loss_fn)\n",
        "  print(f\"Epoch {epoch}: loss={epoch_loss:.4f}, time={epoch_time:.4f}\")\n",
        "\n",
        "# evaluate the model\n",
        "loss, acc = test_step(model, test_loader, loss_fn)\n",
        "print(\"Test Set Performance:\")\n",
        "print(f\"Average Loss: {loss:.3f}\")\n",
        "print(f\"Classification Accuracy: {acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JHqlvUGFxq7",
        "outputId": "79c2e779-8c67-4348-cb78-ce90a0f79a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss=0.0056, time=1.4525\n",
            "Epoch 1: loss=0.0023, time=1.0214\n",
            "Epoch 2: loss=0.0018, time=1.0421\n",
            "Epoch 3: loss=0.0015, time=1.3504\n",
            "Epoch 4: loss=0.0013, time=1.1499\n",
            "Epoch 5: loss=0.0012, time=1.0096\n",
            "Epoch 6: loss=0.0010, time=1.0152\n",
            "Epoch 7: loss=0.0009, time=1.0225\n",
            "Epoch 8: loss=0.0008, time=1.0067\n",
            "Epoch 9: loss=0.0008, time=1.0165\n",
            "Test Set Performance:\n",
            "Average Loss: 0.001\n",
            "Classification Accuracy: 0.968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**: Now that our training is sped up, we spend a bit more time tuning our model and training scheme. So far, we've picked the hyperparameters (e.g. learning rate and momentum in the optimizer, batch size, the size of the hidden layers, the number of hidden layers) somewhat randomly. Try varying them a bit - how does the model performance change? Can you get a better classification accuracy?"
      ],
      "metadata": {
        "id": "bsPuf0_LuOtY"
      }
    }
  ]
}